"""
ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GMOã‚³ã‚¤ãƒ³ã‹ã‚‰éå»ã®OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿å­˜ã™ã‚‹
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from backend.config_manager import get_config_manager
from backend.logger import get_logger
from backend.data_fetcher import GMOCoinRESTFetcher
from backend.data_fetcher.base import DataStorage


async def download_historical_data(symbol: str, interval: str, days: int):
    """
    éå»ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    
    Args:
        symbol: é€šè²¨ãƒšã‚¢
        interval: æ™‚é–“é–“éš”
        days: å–å¾—æ—¥æ•°
    """
    logger = get_logger()
    config = get_config_manager()
    logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {symbol} {interval} éå»{days}æ—¥åˆ†")
    
    async with GMOCoinRESTFetcher() as fetcher:
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
        all_data = []
        
        try:
            # GMOã‚³ã‚¤ãƒ³APIã§éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            # æœ€å¤§1000ä»¶ãšã¤å–å¾—å¯èƒ½
            logger.info(f"GMOã‚³ã‚¤ãƒ³APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆGMOã‚³ã‚¤ãƒ³ã¯æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ã£ã¦å–å¾—ï¼‰
            df = await fetcher.fetch_ohlcv(
                symbol=symbol,
                interval=interval,
                limit=1000  # æœ€å¤§å–å¾—ä»¶æ•°
            )
            
            if not df.empty:
                logger.info(f"å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
                logger.info(f"æœŸé–“: {df['timestamp'].min()} ï½ {df['timestamp'].max()}")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’Parquetå½¢å¼ã§ä¿å­˜
                storage = DataStorage(config)
                storage.save_ohlcv(df, symbol, interval)
                
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {symbol}_{interval}")
                return True
            else:
                logger.error("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return False
                
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='GMOã‚³ã‚¤ãƒ³éå»ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
    parser.add_argument(
        '--symbol',
        default='BTC_JPY',
        help='é€šè²¨ãƒšã‚¢ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: BTC_JPY)'
    )
    parser.add_argument(
        '--interval',
        default='1hour',
        choices=['1min', '5min', '15min', '30min', '1hour', '4hour', '8hour', '12hour', '1day', '1week', '1month'],
        help='æ™‚é–“é–“éš” (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1hour)'
    )
    parser.add_argument(
        '--days',
        type=int,
        default=30,
        help='å–å¾—æ—¥æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥) â€»å®Ÿéš›ã«ã¯APIã®åˆ¶é™ã«ã‚ˆã‚Šæœ€å¤§1000ä»¶'
    )
    
    args = parser.parse_args()
    
    # éåŒæœŸã§å®Ÿè¡Œ
    success = asyncio.run(download_historical_data(
        args.symbol,
        args.interval,
        args.days
    ))
    
    if success:
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
        print(f"ğŸ“ ä¿å­˜å…ˆ: ./data/ohlcv/{args.symbol}_{args.interval}.parquet")
        print(f"ğŸ’¡ Streamlit UIã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã§ãã¾ã™")
    else:
        print(f"\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print(f"âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main()
